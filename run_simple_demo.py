#!/usr/bin/env python3
"""
Simple Demo Runner (No GUI Dependencies)
"""

import sys
import os

# Ø¥Ø¶Ø§ÙØ© Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

def run_simple_demo():
    """ØªØ´ØºÙŠÙ„ Ø¹Ø±Ø¶ ØªÙˆØ¶ÙŠØ­ÙŠ Ø¨Ø³ÙŠØ· Ø¨Ø¯ÙˆÙ† GUI"""
    print("ğŸš Autonomous Medical Drone Delivery - Simple Demo")
    print("=" * 50)
    
    try:
        from src.ai.hybrid_controller import HybridController
        from src.environment.city import CityEnvironment
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¨ÙŠØ¦Ø© ÙˆØ§Ù„Ù…ØªØ­ÙƒÙ…
        env = CityEnvironment()
        controller = HybridController()
        
        print("ğŸŒ Environment created with realistic city simulation")
        print("ğŸ§  Hybrid AI controller initialized (Q-Learning + Logic Engine)")
        print("\nğŸ¯ Starting autonomous missions...\n")
        
        # ØªØ´ØºÙŠÙ„ Ø¹Ø¯Ø© Ù…Ù‡Ø§Ù…
        total_missions = 3
        successful_missions = 0
        
        for mission in range(total_missions):
            print(f"ğŸš€ Mission {mission + 1}/{total_missions}")
            print("-" * 30)
            
            # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø¨ÙŠØ¦Ø©
            state = env.reset()
            total_reward = 0
            steps = 0
            
            # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©
            drone_pos = env.drone.position
            target_pos = env.target_position
            print(f"ğŸ“ Start: ({drone_pos[0]}, {drone_pos[1]}, {drone_pos[2]})")
            print(f"ğŸ¯ Target: ({target_pos[0]}, {target_pos[1]}, {target_pos[2]})")
            print(f"ğŸ”‹ Battery: {state['battery']:.1f}%")
            print(f"ğŸŒ¤ï¸  Weather: {state['weather']} (Safe: {state['safe_to_fly']})")
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø©
            decision_log = []
            
            for step in range(200):  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 200 Ø®Ø·ÙˆØ©
                # Ø§Ø®ØªÙŠØ§Ø± Ø¥Ø¬Ø±Ø§Ø¡ (ÙˆØ¶Ø¹ demo - Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªÙƒØ´Ø§Ù)
                action, decision_info = controller.choose_action(state, training=False)
                
                # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡
                next_state, reward, done, info = env.step(action)
                
                total_reward += reward
                steps += 1
                
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù‚Ø±Ø§Ø±
                decision_log.append({
                    'step': step + 1,
                    'action': action,
                    'reward': reward,
                    'decision_type': decision_info['decision_type'],
                    'battery': state['battery'],
                    'position': state['position']
                })
                
                # Ø·Ø¨Ø§Ø¹Ø© Ù…Ø¹Ù„ÙˆÙ…Ø§Øª ÙƒÙ„ 25 Ø®Ø·ÙˆØ©
                if (step + 1) % 25 == 0:
                    print(f"  Step {step + 1:3d}: {action:12s} | "
                          f"Reward: {reward:6.1f} | "
                          f"Battery: {state['battery']:5.1f}% | "
                          f"Type: {decision_info['decision_type']}")
                
                state = next_state
                
                if done:
                    break
            
            # Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ù‡Ù…Ø©
            success = info.get('success', False)
            reason = info.get('reason', 'Unknown')
            
            if success:
                successful_missions += 1
                print(f"âœ… SUCCESS: {reason}")
            else:
                print(f"âŒ FAILED: {reason}")
            
            print(f"ğŸ“Š Total Reward: {total_reward:.1f}")
            print(f"ğŸ“Š Steps Taken: {steps}")
            print(f"ğŸ“Š Final Battery: {next_state['battery']:.1f}%")
            
            # Ø¹Ø±Ø¶ Ø¢Ø®Ø± 5 Ù‚Ø±Ø§Ø±Ø§Øª
            print("ğŸ§  Last 5 Decisions:")
            for decision in decision_log[-5:]:
                print(f"  Step {decision['step']:3d}: {decision['action']:12s} "
                      f"({decision['decision_type']}) -> Reward: {decision['reward']:6.1f}")
            
            print()
        
        # Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        print("=" * 50)
        print("ğŸ‰ DEMO COMPLETED!")
        print(f"ğŸ“Š Success Rate: {successful_missions}/{total_missions} "
              f"({successful_missions/total_missions*100:.1f}%)")
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ­ÙƒÙ…
        stats = controller.get_statistics()
        print(f"ğŸ§  AI Statistics:")
        print(f"   Total Decisions: {stats['hybrid_controller']['decisions_made']}")
        print(f"   Safety Overrides: {stats['hybrid_controller']['safety_overrides']}")
        print(f"   Q-Table Size: {stats['q_learning']['q_table_size']}")
        print(f"   Logic Rules: {stats['logic_engine']['total_rules']}")
        
        if successful_missions > 0:
            print("\nâœ¨ The hybrid AI successfully demonstrated:")
            print("   ğŸ§  Learning-based navigation (Q-Learning)")
            print("   âš–ï¸ Safety-critical rule enforcement")
            print("   ğŸ”„ Real-time decision making")
            print("   ğŸ“Š Explainable AI decisions")
        
        return True
        
    except KeyboardInterrupt:
        print("\nğŸ‘‹ Demo interrupted by user")
        return False
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
    os.makedirs("data", exist_ok=True)
    os.makedirs("data/models", exist_ok=True)
    os.makedirs("data/logs", exist_ok=True)
    
    success = run_simple_demo()
    
    if success:
        print("\nğŸ¯ Next Steps:")
        print("1. Run training: python run_training.py")
        print("2. Install GUI deps: pip install pygame PyQt5")
        print("3. Run full GUI: python run_gui.py")
    else:
        sys.exit(1)