"""
Training Module for Hybrid Drone Controller
"""

import os
import time
import json
from typing import Dict, List
import matplotlib.pyplot as plt
import numpy as np

from .hybrid_controller import HybridController
from ..environment.city import CityEnvironment
from ..utils.config import (
    NUM_EPISODES, MODELS_DIR, DATA_DIR, 
    SAVE_INTERVAL, PLOT_INTERVAL
)
from ..utils.logger import get_logger
from ..utils.metrics import MetricsTracker


class DroneTrainer:
    """
    Ù…Ø¯Ø±Ø¨ Ø§Ù„Ø·Ø§Ø¦Ø±Ø© Ø§Ù„Ù…Ø³ÙŠØ±Ø©
    
    ÙŠØ¯ÙŠØ± Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙƒØ§Ù…Ù„Ø©:
    - ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªØ­ÙƒÙ… Ø§Ù„Ù‡Ø¬ÙŠÙ†
    - ØªØªØ¨Ø¹ Ø§Ù„Ø£Ø¯Ø§Ø¡
    - Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
    - Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
    """
    
    def __init__(self, config: Dict = None):
        """
        ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø¯Ø±Ø¨
        
        Args:
            config: Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ (Ø£Ùˆ None Ù„Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©)
        """
        self.config = config or {}
        
        # Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        self.env = CityEnvironment()
        self.controller = HybridController()
        self.metrics = MetricsTracker()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        self.num_episodes = self.config.get('num_episodes', NUM_EPISODES)
        self.save_interval = self.config.get('save_interval', SAVE_INTERVAL)
        self.plot_interval = self.config.get('plot_interval', PLOT_INTERVAL)
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        self.episode_rewards = []
        self.episode_steps = []
        self.success_rates = []
        self.safety_override_rates = []
        
        self.logger = get_logger()
        self.logger.info("Drone Trainer initialized")
    
    def train(self, resume: bool = False) -> Dict:
        """
        Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        
        Args:
            resume: Ù‡Ù„ Ù†Ø³ØªÙƒÙ…Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù†Ù…ÙˆØ°Ø¬ Ù…Ø­ÙÙˆØ¸ØŸ
        
        Returns:
            Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        """
        self.logger.info(f"Starting training for {self.num_episodes} episodes")
        
        # ØªØ­Ù…ÙŠÙ„ Ù†Ù…ÙˆØ°Ø¬ Ø³Ø§Ø¨Ù‚ Ø¥Ø°Ø§ Ø·ÙÙ„Ø¨
        if resume:
            self.controller.load_models()
        
        # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØªØ¨Ø¹
        start_time = time.time()
        recent_rewards = []  # Ø¢Ø®Ø± 100 Ø­Ù„Ù‚Ø©
        recent_successes = []  # Ø¢Ø®Ø± 100 Ø­Ù„Ù‚Ø©
        
        try:
            for episode in range(self.num_episodes):
                episode_start = time.time()
                
                # ØªØ¯Ø±ÙŠØ¨ Ø­Ù„Ù‚Ø© ÙˆØ§Ø­Ø¯Ø©
                episode_stats = self.controller.train_episode(self.env)
                
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                self.episode_rewards.append(episode_stats['total_reward'])
                self.episode_steps.append(episode_stats['steps'])
                
                recent_rewards.append(episode_stats['total_reward'])
                recent_successes.append(1 if episode_stats['success'] else 0)
                
                # Ø§Ù„Ø§Ø­ØªÙØ§Ø¸ Ø¨Ø¢Ø®Ø± 100 Ø­Ù„Ù‚Ø© ÙÙ‚Ø·
                if len(recent_rewards) > 100:
                    recent_rewards.pop(0)
                    recent_successes.pop(0)
                
                # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù…Ø¹Ø¯Ù„Ø§Øª
                avg_reward = np.mean(recent_rewards)
                success_rate = np.mean(recent_successes) * 100
                
                self.success_rates.append(success_rate)
                
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…ØªØ­ÙƒÙ…
                controller_stats = self.controller.get_statistics()
                safety_rate = controller_stats['hybrid_controller']['safety_override_rate'] * 100
                self.safety_override_rates.append(safety_rate)
                
                # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø¯Ù…
                if episode % 10 == 0 or episode == self.num_episodes - 1:
                    episode_time = time.time() - episode_start
                    self._print_progress(episode, episode_stats, avg_reward, 
                                       success_rate, safety_rate, episode_time)
                
                # Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
                if episode % self.save_interval == 0 and episode > 0:
                    self._save_checkpoint(episode)
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³ÙˆÙ… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠØ©
                if episode % self.plot_interval == 0 and episode > 0:
                    self._plot_training_progress(episode)
                
                # ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ù…Ù‚Ø§ÙŠÙŠØ³
                self.metrics.log_episode(
                    episode=episode,
                    reward=episode_stats['total_reward'],
                    steps=episode_stats['steps'],
                    success=episode_stats['success'],
                    safety_overrides=episode_stats['safety_overrides']
                )
        
        except KeyboardInterrupt:
            self.logger.info("Training interrupted by user")
        
        # Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        total_time = time.time() - start_time
        final_stats = self._finalize_training(total_time)
        
        return final_stats
    
    def _print_progress(self, episode: int, episode_stats: Dict, 
                       avg_reward: float, success_rate: float, 
                       safety_rate: float, episode_time: float):
        """Ø·Ø¨Ø§Ø¹Ø© ØªÙ‚Ø¯Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        print(f"\nğŸ“Š Episode {episode + 1}/{self.num_episodes}")
        print(f"   Reward: {episode_stats['total_reward']:.1f} | "
              f"Steps: {episode_stats['steps']} | "
              f"Success: {'âœ…' if episode_stats['success'] else 'âŒ'}")
        print(f"   Avg Reward (100): {avg_reward:.1f} | "
              f"Success Rate: {success_rate:.1f}% | "
              f"Safety Rate: {safety_rate:.1f}%")
        print(f"   Epsilon: {self.controller.q_agent.epsilon:.3f} | "
              f"Time: {episode_time:.2f}s")
    
    def _save_checkpoint(self, episode: int):
        """Ø­ÙØ¸ Ù†Ù‚Ø·Ø© ØªÙØªÙŠØ´"""
        checkpoint_dir = os.path.join(MODELS_DIR, f"checkpoint_{episode}")
        os.makedirs(checkpoint_dir, exist_ok=True)
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬
        q_table_path = os.path.join(checkpoint_dir, "q_table.pkl")
        self.controller.save_models(q_table_path)
        
        # Ø­ÙØ¸ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
        stats_path = os.path.join(checkpoint_dir, "training_stats.json")
        stats = {
            'episode': episode,
            'episode_rewards': self.episode_rewards,
            'episode_steps': self.episode_steps,
            'success_rates': self.success_rates,
            'safety_override_rates': self.safety_override_rates
        }
        
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats, f, indent=2, ensure_ascii=False)
        
        self.logger.info(f"Checkpoint saved at episode {episode}")
    
    def _plot_training_progress(self, episode: int):
        """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³ÙˆÙ… Ø¨ÙŠØ§Ù†ÙŠØ© Ù„Ù„ØªÙ‚Ø¯Ù…"""
        if len(self.episode_rewards) < 10:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 10))
        fig.suptitle(f'Training Progress - Episode {episode + 1}', fontsize=16)
        
        # 1. Ø§Ù„Ù…ÙƒØ§ÙØ¢Øª
        axes[0, 0].plot(self.episode_rewards, alpha=0.6, color='blue')
        if len(self.episode_rewards) >= 10:
            # Ù…ØªÙˆØ³Ø· Ù…ØªØ­Ø±Ùƒ
            window = min(50, len(self.episode_rewards) // 4)
            moving_avg = np.convolve(self.episode_rewards, 
                                   np.ones(window)/window, mode='valid')
            axes[0, 0].plot(range(window-1, len(self.episode_rewards)), 
                           moving_avg, color='red', linewidth=2)
        
        axes[0, 0].set_title('Episode Rewards')
        axes[0, 0].set_xlabel('Episode')
        axes[0, 0].set_ylabel('Total Reward')
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. Ø¹Ø¯Ø¯ Ø§Ù„Ø®Ø·ÙˆØ§Øª
        axes[0, 1].plot(self.episode_steps, alpha=0.6, color='green')
        axes[0, 1].set_title('Episode Steps')
        axes[0, 1].set_xlabel('Episode')
        axes[0, 1].set_ylabel('Steps')
        axes[0, 1].grid(True, alpha=0.3)
        
        # 3. Ù…Ø¹Ø¯Ù„ Ø§Ù„Ù†Ø¬Ø§Ø­
        if len(self.success_rates) > 0:
            axes[1, 0].plot(self.success_rates, color='orange', linewidth=2)
            axes[1, 0].set_title('Success Rate (%)')
            axes[1, 0].set_xlabel('Episode')
            axes[1, 0].set_ylabel('Success Rate')
            axes[1, 0].set_ylim(0, 100)
            axes[1, 0].grid(True, alpha=0.3)
        
        # 4. Ù…Ø¹Ø¯Ù„ ØªØ¯Ø®Ù„ Ø§Ù„Ø£Ù…Ø§Ù†
        if len(self.safety_override_rates) > 0:
            axes[1, 1].plot(self.safety_override_rates, color='red', linewidth=2)
            axes[1, 1].set_title('Safety Override Rate (%)')
            axes[1, 1].set_xlabel('Episode')
            axes[1, 1].set_ylabel('Override Rate')
            axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # Ø­ÙØ¸ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ
        plots_dir = os.path.join(DATA_DIR, 'plots')
        os.makedirs(plots_dir, exist_ok=True)
        
        plot_path = os.path.join(plots_dir, f'training_progress_{episode}.png')
        plt.savefig(plot_path, dpi=300, bbox_inches='tight')
        plt.close()
        
        self.logger.info(f"Training plot saved: {plot_path}")
    
    def _finalize_training(self, total_time: float) -> Dict:
        """Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        
        # Ø­ÙØ¸ Ø§Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        self.controller.save_models()
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¨ÙŠØ§Ù†ÙŠ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        self._plot_training_progress(len(self.episode_rewards) - 1)
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©
        final_stats = {
            'training_completed': True,
            'total_episodes': len(self.episode_rewards),
            'total_time_minutes': total_time / 60,
            'average_reward': np.mean(self.episode_rewards[-100:]) if self.episode_rewards else 0,
            'final_success_rate': self.success_rates[-1] if self.success_rates else 0,
            'final_safety_rate': self.safety_override_rates[-1] if self.safety_override_rates else 0,
            'controller_stats': self.controller.get_statistics()
        }
        
        # Ø­ÙØ¸ Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        report_path = os.path.join(DATA_DIR, 'final_training_report.json')
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(final_stats, f, indent=2, ensure_ascii=False)
        
        # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
        self._print_final_report(final_stats)
        
        self.logger.info("Training completed successfully!")
        return final_stats
    
    def _print_final_report(self, stats: Dict):
        """Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"""
        print("\n" + "="*60)
        print("ğŸ¯ TRAINING COMPLETED!")
        print("="*60)
        print(f"ğŸ“Š Total Episodes: {stats['total_episodes']}")
        print(f"â±ï¸  Total Time: {stats['total_time_minutes']:.1f} minutes")
        print(f"ğŸ† Final Success Rate: {stats['final_success_rate']:.1f}%")
        print(f"ğŸ›¡ï¸  Safety Override Rate: {stats['final_safety_rate']:.1f}%")
        print(f"ğŸ’° Average Reward (last 100): {stats['average_reward']:.1f}")
        
        controller_stats = stats['controller_stats']
        print(f"\nğŸ§  Q-Learning Stats:")
        print(f"   Q-Table Size: {controller_stats['q_learning']['q_table_size']}")
        print(f"   Total Updates: {controller_stats['q_learning']['total_updates']}")
        print(f"   Final Epsilon: {controller_stats['q_learning']['epsilon']:.3f}")
        
        print(f"\nâš–ï¸  Logic Engine Stats:")
        print(f"   Total Rules: {controller_stats['logic_engine']['total_rules']}")
        print(f"   Safety Rules: {controller_stats['logic_engine']['rule_types']['safety']}")
        
        print(f"\nğŸ”„ Hybrid Controller Stats:")
        print(f"   Total Decisions: {controller_stats['hybrid_controller']['decisions_made']}")
        print(f"   Safety Overrides: {controller_stats['hybrid_controller']['safety_overrides']}")
        print("="*60)
    
    def evaluate(self, num_episodes: int = 10) -> Dict:
        """
        ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø¯Ø±Ø¨
        
        Args:
            num_episodes: Ø¹Ø¯Ø¯ Ø­Ù„Ù‚Ø§Øª Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        
        Returns:
            Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ…
        """
        self.logger.info(f"Evaluating model for {num_episodes} episodes")
        
        # ØªØ­Ù…ÙŠÙ„ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
        self.controller.load_models()
        
        results = []
        
        for episode in range(num_episodes):
            state = self.env.reset()
            total_reward = 0
            steps = 0
            
            while steps < 1000:  # Ø­Ø¯ Ø£Ù‚ØµÙ‰ Ù„Ù„Ø®Ø·ÙˆØ§Øª
                # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¬Ø´Ø¹ (Ø¨Ø¯ÙˆÙ† Ø§Ø³ØªÙƒØ´Ø§Ù)
                action, decision_info = self.controller.choose_action(state, training=False)
                
                next_state, reward, done, info = self.env.step(action)
                
                total_reward += reward
                steps += 1
                state = next_state
                
                if done:
                    break
            
            results.append({
                'episode': episode,
                'reward': total_reward,
                'steps': steps,
                'success': info.get('success', False)
            })
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        eval_stats = {
            'num_episodes': num_episodes,
            'average_reward': np.mean([r['reward'] for r in results]),
            'success_rate': np.mean([r['success'] for r in results]) * 100,
            'average_steps': np.mean([r['steps'] for r in results]),
            'results': results
        }
        
        self.logger.info(f"Evaluation completed: {eval_stats['success_rate']:.1f}% success rate")
        return eval_stats


def main():
    """Ø¯Ø§Ù„Ø© Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
    trainer = DroneTrainer()
    
    # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    final_stats = trainer.train()
    
    # ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
    eval_stats = trainer.evaluate()
    
    print(f"\nğŸ‰ Training and evaluation completed!")
    print(f"Final success rate: {eval_stats['success_rate']:.1f}%")


if __name__ == "__main__":
    main()